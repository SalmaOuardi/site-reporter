# Site Reporter MVP - Project Context & Current Status

## ğŸ“‹ Project Overview

**Goal:** Create a minimal but functional full-stack Python project (FastAPI + Streamlit) for a construction-site report generator MVP that converts French audio recordings into structured reports.

**Tech Stack:**
- Backend: FastAPI (Python 3.11+)
- Frontend: Streamlit
- STT: Azure OpenAI GPT-4o-mini-transcribe
- LLM: Azure OpenAI Mistral-small-2503
- Dependency Management: UV (not pip)
- Language: French (all UI, reports, and transcriptions)

---

## ğŸ—ï¸ Project Structure

```
site-reporter/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env                        # Azure API keys
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ pyproject.toml              # Backend dependencies
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py                 # FastAPI app
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â””â”€â”€ config.py           # Azure OpenAI configuration
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚       â”œâ”€â”€ routers/
â”‚       â”‚   â””â”€â”€ pipeline.py         # API endpoints
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ llm.py              # Azure Mistral LLM service
â”‚           â”œâ”€â”€ stt.py              # Azure STT service
â”‚           â”œâ”€â”€ template.py         # LLM-powered field extraction
â”‚           â””â”€â”€ report.py           # French report generation
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                      # Streamlit app (French UI)
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ api.py                  # Backend API client
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ integration/
    â”‚   â””â”€â”€ test_azure_integration.py
    â””â”€â”€ fixtures/
        â””â”€â”€ audio/
            â””â”€â”€ test_audio.wav
```

---

## âœ… What We've Completed

### 1. Azure OpenAI Integration âœ…
- **STT Service:** Uses Azure GPT-4o-mini-transcribe for French audio transcription
- **LLM Service:** Uses Azure Mistral-small-2503 for intelligent field extraction
- **Configuration:**
  - Endpoint: `https://draftspeechtotext.cognitiveservices.azure.com`
  - STT API Version: `2025-03-01-preview`
  - Mistral API Version: `2024-05-01-preview`
  - Default Language: French (`fr`)

### 2. French Language Implementation âœ…
- All UI elements translated to French
- French report templates
- French keyword detection
- French LLM prompts for field extraction

### 3. Template System âœ…
Four French report templates implemented:

**Template 1: `probleme_decouverte` (Problem/Incident)**
- Keywords: problÃ¨me, incident, souci, dÃ©faillance, panne, fuite, casse
- Fields: Date, Heure, OpÃ©rateur, ProblÃ¨me, Domaine, Urgence, Plan d'action

**Template 2: `tour_securite` (Security Tour)**
- Keywords: tour, sÃ©curitÃ©, inspection, vendredi, fissure, bÃ©ton
- Fields: Date, Heure, OpÃ©rateur, Zone inspectÃ©e, Observations, Non-conformitÃ©s, Actions correctives

**Template 3: `tache_assignee` (Task Assignment)**
- Keywords: tÃ¢che, assignÃ©, mission, travail
- Fields: Date, Heure, OpÃ©rateur, TÃ¢che, AssignÃ© Ã , Ã‰chÃ©ance, PrioritÃ©, Description

**Template 4: `rapport_generique` (Generic - Default)**
- Fields: Date, Heure, OpÃ©rateur, ProblÃ¨me, Domaine, Urgence, Plan d'action

### 4. LLM-Powered Field Extraction âœ…
- Template detection uses French keywords
- Mistral LLM extracts structured data from transcript
- Low temperature (0.1) for factual extraction
- JSON response parsing with markdown cleanup
- Fallback handling for LLM failures

### 5. Two Workflow Modes âœ…
**Mode 1: Avec validation humaine (Human-in-loop)**
1. Record/upload audio
2. Transcribe audio
3. Infer template and extract fields
4. Edit fields in interactive table
5. Generate final report

**Mode 2: EntiÃ¨rement automatique (Fully automatic)**
1. Record/upload audio
2. Click "Lancer le pipeline automatique"
3. Everything happens automatically

### 6. Auto-Reload Configured âœ…
- Backend: `--reload` flag enabled
- Frontend: Streamlit watches for file changes

### 7. Project Cleanup âœ…
- Removed duplicate `backend/backend/` directory
- Moved tests to proper `tests/` structure
- Enhanced `.gitignore`
- Standardized Python version to 3.11+
- Added pytest configuration

---

## ğŸ”§ Current Configuration

### Backend Environment Variables (`.env`)
```env
# Azure OpenAI Configuration
AZURE_OPENAI_KEY="<your-key>"
AZURE_ENDPOINT="https://draftspeechtotext.cognitiveservices.azure.com"

# Speech-to-Text Configuration
STT_DEPLOYMENT_NAME="gpt-4o-mini-transcribe"
STT_API_VERSION="2025-03-01-preview"
DEFAULT_LANGUAGE="fr"

# LLM Configuration (Mistral)
MISTRAL_DEPLOYMENT_NAME="mistral-small-2503"
MISTRAL_API_VERSION="2024-05-01-preview"

# Application Configuration
DEFAULT_TEMPLATE="rapport_generique"
```

### API Endpoints
- `POST /api/transcribe` - Transcribe audio
- `POST /api/report/template` - Infer template and extract fields
- `POST /api/report/generate` - Generate final report
- `POST /api/pipeline/auto` - Full automatic pipeline
- `GET /health` - Health check

---

## ğŸ¯ How It Should Work

### Expected Workflow (Avec validation humaine)

**Input Example:**
> "Aujourd'hui, le 12 novembre 2025, je fais l'inspection du bÃ¢timent A. Je me trouve actuellement au troisiÃ¨me Ã©tage devant l'entrÃ©e principale. J'ai remarquÃ© trois fissures importantes sur le mur est. Les fissures mesurent environ 15 Ã  20 cm de longueur. L'Ã©tat du bÃ©ton armÃ© semble prÃ©occupant. Je recommande une inspection dÃ©taillÃ©e par un ingÃ©nieur structure."

**Expected Output:**
1. **Template Detection:** `tour_securite` (detected via keywords: "inspection", "fissure", "bÃ©ton")
2. **Extracted Fields:**
   - Date: `12/11/2025`
   - Heure: *(empty if not mentioned)*
   - OpÃ©rateur: `Marie Martin - Responsable sÃ©curitÃ©`
   - Zone inspectÃ©e: `BÃ¢timent A, troisiÃ¨me Ã©tage, entrÃ©e principale`
   - Observations: `Trois fissures importantes sur le mur est, 15-20 cm de longueur`
   - Non-conformitÃ©s: `Ã‰tat du bÃ©ton armÃ© prÃ©occupant`
   - Actions correctives: `Inspection dÃ©taillÃ©e par un ingÃ©nieur structure recommandÃ©e`

3. **Generated Report:**
```
============================================================
RAPPORT DE SÃ‰CURITÃ‰ - Tour de Chantier
============================================================
GÃ©nÃ©rÃ© le: 12/11/2025 Ã  16:54

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DÃ‰TAILS DU RAPPORT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â–ª Date: 12/11/2025
â–ª Heure: Non renseignÃ©
â–ª OpÃ©rateur: Marie Martin - Responsable sÃ©curitÃ©
â–ª Zone inspectÃ©e: BÃ¢timent A, troisiÃ¨me Ã©tage, entrÃ©e principale
â–ª Observations: Trois fissures importantes sur le mur est, 15-20 cm
â–ª Non-conformitÃ©s: Ã‰tat du bÃ©ton armÃ© prÃ©occupant
â–ª Actions correctives: Inspection dÃ©taillÃ©e par un ingÃ©nieur structure

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TRANSCRIPTION AUDIO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Aujourd'hui, le 12 novembre 2025, je fais l'inspection...
```

---

## âŒ Current Problem

### Issue: "Avec validation humaine" Mode - Transcript Not Displaying

**Symptoms:**
1. User records audio âœ…
2. User clicks "ğŸ“ Transcrire l'audio" button
3. Toast notification appears: "âœ… Transcription reÃ§ue" âœ…
4. **But the transcript text does NOT appear in the text area** âŒ
5. If user switches to "EntiÃ¨rement automatique" mode and clicks "Lancer le pipeline", everything works perfectly âœ…
6. After that, if user returns to "Avec validation humaine", the transcript suddenly appears âœ…

**What Works:**
- âœ… "EntiÃ¨rement automatique" mode works perfectly
- âœ… Audio recording/upload works
- âœ… Backend transcription service works (confirmed by automatic mode)
- âœ… Session state is being updated (confirmed by mode switching behavior)
- âœ… LLM field extraction works
- âœ… Report generation works

**What Doesn't Work:**
- âŒ UI doesn't refresh/update after transcription in "Avec validation humaine" mode
- âŒ Transcript text area remains empty immediately after transcription
- âŒ User has to switch modes or trigger another action to see the transcript

### What We've Tried

**Attempt 1: Added `st.rerun()` to force UI refresh**
```python
def handle_transcription(audio_bytes: bytes, language: Optional[str]) -> None:
    encoded = encode_audio(audio_bytes)
    try:
        with st.spinner("ğŸ”„ Transcription en cours avec GPT-4o-mini..."):
            response = client.transcribe(encoded, language=language)
    except Exception as exc:
        st.error(f"âŒ Ã‰chec de la transcription: {exc}")
        return
    st.session_state["transcript"] = response["text"]
    st.toast("âœ… Transcription reÃ§ue.", icon="âœï¸")
    st.rerun()  # Force UI refresh to show transcript
```

**Attempt 2: Use session_state audio instead of local variable**
```python
# Before (didn't work after rerun):
if st.button("ğŸ“ Transcrire l'audio", disabled=audio_bytes is None):
    handle_transcription(audio_bytes, ...)

# After (to persist audio across reruns):
stored_audio = st.session_state.get("audio_bytes")
if st.button("ğŸ“ Transcrire l'audio", disabled=stored_audio is None):
    handle_transcription(stored_audio, ...)
```

**Result:** Problem persists âŒ

### Technical Details

**Transcript Storage:**
```python
st.session_state["transcript"] = response["text"]  # Confirmed working
```

**Transcript Display:**
```python
new_transcript = st.text_area(
    "Transcription (modifiable):",
    value=st.session_state.get("transcript", ""),  # Should show transcript
    height=120,
    key="transcript_editor",
)
```

**Hypothesis:**
The issue might be related to:
1. Streamlit widget state management across reruns
2. Text area not re-rendering with new value
3. Race condition between session_state update and widget rendering
4. Button click consuming the rerun before text area updates

### Code Location

**Frontend file:** `frontend/app.py`
- Line 83-95: `handle_transcription()` function
- Line 207-221: "Avec validation humaine" mode UI
- Line 211-216: Transcription button and handler

**Backend files (working correctly):**
- `backend/app/services/stt.py` - STT service
- `backend/app/services/template.py` - LLM field extraction
- `backend/app/routers/pipeline.py` - API endpoints

---

## ğŸš€ How to Run

### Terminal 1 - Backend
```bash
cd backend
uv run uvicorn app.main:app --reload
```
Server runs at: `http://127.0.0.1:8000`

### Terminal 2 - Frontend
```bash
cd frontend
uv run streamlit run app.py
```
App opens at: `http://localhost:8501`

### Testing Azure Integration
```bash
uv run --directory backend python tests/integration/test_azure_integration.py tests/fixtures/audio/test_audio.wav
```

---

## ğŸ“ Next Steps After Fixing Current Issue

1. **Enhance LLM field extraction prompts** for better accuracy
2. **Add PDF generation** (currently placeholder)
3. **Add persistence layer** (database for reports)
4. **Add authentication**
5. **Add unit tests**
6. **Improve error handling and user feedback**
7. **Add logging and monitoring**

---

## ğŸ”‘ Key Files for Reference

### Frontend State Management
**File:** `frontend/app.py`
```python
def init_state() -> None:
    defaults = {
        "mode": "Avec validation humaine",
        "transcript": "",
        "template_type": "",
        "fields": {},
        "report_text": "",
        "audio_bytes": None,
        "language": "fr",
    }
```

### Backend LLM Extraction
**File:** `backend/app/services/template.py`
- Uses 2-step process: keyword detection â†’ LLM extraction
- French prompts with low temperature (0.1)
- Async function returning `Tuple[str, Dict[str, str]]`

### API Client
**File:** `frontend/services/api.py`
```python
class BackendClient:
    def transcribe(self, audio_b64: str, language: str = None) -> dict
    def infer_template(self, transcript: str) -> dict
    def generate_report(self, template_type: str, fields: dict, transcript: str = None) -> dict
    def run_auto_pipeline(self, audio_b64: str, language: str = None) -> dict
```

---

## ğŸ› Debug Information

**Streamlit Version:** `>=1.36.0`
**Python Version:** `3.11+`
**UV Version:** Latest

**Session State Keys:**
- `mode`: Current workflow mode
- `transcript`: Transcribed text
- `template_type`: Detected template
- `fields`: Extracted field dictionary
- `report_text`: Generated report
- `audio_bytes`: Raw audio data
- `language`: Selected language (default: "fr")

**Known Working Flows:**
1. âœ… Automatic mode â†’ Complete success
2. âœ… Manual mode â†’ Switch to auto â†’ Switch back â†’ Shows transcript
3. âŒ Manual mode â†’ Transcribe â†’ (empty text area)

---

## ğŸ“ Contact & Context

This document was created to provide context for debugging the Streamlit UI refresh issue in the "Avec validation humaine" workflow mode. The backend is working correctly, Azure integration is functional, and the automatic mode works perfectly. The issue is isolated to the frontend UI state management after transcription.

**Date:** November 12, 2025
**Status:** MVP functional except for UI refresh bug in manual mode
